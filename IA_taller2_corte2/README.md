# ğŸ“Š TALLER II SEGUNDO CORTE: ANÃLISIS DE DATOS CON PYTHON

## ğŸ›ï¸ InformaciÃ³n AcadÃ©mica
**Universidad:** Universidad del PacÃ­fico  
**Carrera o Programa:** IngenierÃ­a en Sistemas  
**Asignatura:** Inteligencia Artificial (IA)

### ğŸ‘¥ Integrantes del Grupo:
- ANDRES STEVEN RIVAS SALAS  
- KEVIN JOSEPH VALBUENA PÃ‰REZ  
- RUBEN DARIO BARONA  

---

## ğŸ¯ Objetivo del Trabajo
El objetivo principal de este taller es aplicar los fundamentos de la programaciÃ³n en **Python** para la manipulaciÃ³n y anÃ¡lisis de datos, utilizando las librerÃ­as especializadas **NumPy**, **Pandas**, **SciPy** y **Matplotlib**.  
En particular, se busca:

- Dominar el uso de estructuras numÃ©ricas y estadÃ­sticas en NumPy.  
- Analizar y limpiar datos reales en Pandas.  
- Generar visualizaciones interpretativas (barras, dispersiÃ³n, histogramas).  
- Aplicar conceptos estadÃ­sticos como sesgo, curtosis, pruebas de hipÃ³tesis y correlaciones.  
- Validar supuestos de normalidad e independencia de variables mediante pruebas estadÃ­sticas.

---

## ğŸ’¡ DescripciÃ³n del Proyecto o Taller
Este proyecto se desarrolla en **Google Colab** a travÃ©s de un **Notebook (.ipynb)** que contiene ejercicios prÃ¡cticos organizados en seis bloques temÃ¡ticos:

1. **Medidas de forma:** cÃ¡lculo de sesgo y curtosis en notas de estudiantes.  
2. **Teorema del LÃ­mite Central:** demostraciÃ³n de la normalidad muestral.  
3. **Distribuciones de probabilidad:** ejemplos reales con distribuciÃ³n Exponencial y Poisson.  
4. **Correlaciones:** anÃ¡lisis de relaciones positiva, negativa y nula con datos sintÃ©ticos.  
5. **Pruebas de normalidad:** comparaciÃ³n entre muestras normales y no normales (Shapiroâ€“Wilk).  
6. **Prueba de independencia:** test Chi-cuadrado aplicado a variables categÃ³ricas.

ğŸ“„ Notebook:  
ğŸ”— [Taller2_segundo_corte_AI.ipynb](https://colab.research.google.com/github/asrivasSW/AI-CLASS/blob/main/IA_taller2_corte2/Taller2_segundo_corte_AI.ipynb)

---

## ğŸ› ï¸ TecnologÃ­as Utilizadas

| LibrerÃ­a / TecnologÃ­a | VersiÃ³n (opcional) | FunciÃ³n Principal |
|-----------------------|-------------------|-------------------|
| **Python** | 3.x | Lenguaje de programaciÃ³n principal |
| **NumPy (np)** | - | Operaciones numÃ©ricas y manejo de arreglos |
| **Pandas (pd)** | - | ManipulaciÃ³n y anÃ¡lisis de datos estructurados |
| **Matplotlib (plt)** | - | VisualizaciÃ³n de datos y grÃ¡ficos |
| **Seaborn (sns)** | - | GrÃ¡ficos estadÃ­sticos avanzados |
| **SciPy (stats)** | - | Pruebas estadÃ­sticas y distribuciones de probabilidad |
| **scikit-learn** | - | Modelado y regresiÃ³n lineal |

---

## ğŸ’» Desarrollo y MetodologÃ­a Aplicada
El taller siguiÃ³ una **metodologÃ­a de AnÃ¡lisis Exploratorio de Datos (EDA)**, con las siguientes etapas:

1. **PreparaciÃ³n del entorno:** ImportaciÃ³n de librerÃ­as y montaje del entorno en Google Drive.  
2. **AnÃ¡lisis descriptivo:** CÃ¡lculo de sesgo, curtosis, media y desviaciÃ³n estÃ¡ndar.  
3. **Distribuciones:** SimulaciÃ³n y ajuste de modelos Exponencial y Poisson, incluyendo pruebas de bondad de ajuste (K-S y ChiÂ²).  
4. **VisualizaciÃ³n:** CreaciÃ³n de histogramas, diagramas de dispersiÃ³n y curvas teÃ³ricas.  
5. **CorrelaciÃ³n:** EvaluaciÃ³n de relaciones lineales positivas, negativas y nulas entre variables.  
6. **Inferencia estadÃ­stica:** AplicaciÃ³n de pruebas de normalidad e independencia para validar supuestos.

---

## ğŸ” InterpretaciÃ³n y AnÃ¡lisis de Resultados

### ğŸ“Š Medidas de Forma
El **sesgo (-0.246)** indica una ligera asimetrÃ­a hacia la izquierda, mientras que la **curtosis (-1.143)** refleja una distribuciÃ³n **platicÃºrtica**, es decir, mÃ¡s aplanada que la normal.  
Esto sugiere una concentraciÃ³n moderada de calificaciones alrededor de la media (â‰ˆ3.90).

---

### ğŸ“ˆ Teorema del LÃ­mite Central
A medida que el tamaÃ±o de las muestras aumenta (n=5, 30, 100), las distribuciones de las medias muestrales se aproximan a una **distribuciÃ³n normal**, incluso cuando la poblaciÃ³n original es uniforme.  
Esto confirma empÃ­ricamente el **Teorema del LÃ­mite Central**, base fundamental de la estadÃ­stica inferencial.

---

### ğŸ“‰ Distribuciones de Probabilidad
- **Exponencial (tiempos de espera entre clientes):**  
  Media empÃ­rica = 6.086, desviaciÃ³n estÃ¡ndar = 6.166.  
  Prueba K-S: p-valor = 0.8967 â†’ no se rechaza Hâ‚€ â†’ buen ajuste.  

- **Poisson (emails por hora):**  
  Media empÃ­rica = 3.984, p-valor (ChiÂ²) = 0.4695 â†’ ajuste adecuado.  

Ambos modelos representan correctamente fenÃ³menos del mundo real: el **tiempo entre eventos** y el **conteo de sucesos discretos**.

---

### ğŸ”— Correlaciones
- **Positiva:** Horas de estudio vs calificaciÃ³n (r = 0.97) â†’ A mayor estudio, mejor rendimiento.  
- **Negativa:** Temperatura vs ventas de chocolate (r = -0.96) â†’ A mayor temperatura, menores ventas.  
- **Nula:** Zapatos vendidos vs accidentes â†’ No existe relaciÃ³n entre las variables.

---

### ğŸ§ª Test de HipÃ³tesis â€” Prueba de Normalidad
Se generaron dos muestras:
- **Xâ‚ (Uniforme):** p = 0.001 â†’ no es normal.  
- **Xâ‚‚ (Normal):** p = 0.0857 â†’ sÃ­ es normal.  

El **test de Shapiroâ€“Wilk** demuestra que esta prueba es adecuada para determinar si una muestra proviene o no de una distribuciÃ³n normal, requisito clave para anÃ¡lisis paramÃ©tricos.

---

### âš–ï¸ Prueba de Independencia
Se construyÃ³ una tabla de contingencia entre las variables **â€œFumaâ€** y **â€œTos CrÃ³nicaâ€**.  
El **test Chi-cuadrado** obtuvo:  
Ï‡Â² = 2.5802, p = 0.1082 â†’ no se rechaza Hâ‚€.  

Esto indica que **no existe una asociaciÃ³n estadÃ­sticamente significativa** entre ambas variables, mostrando independencia entre los factores analizados.

---

## âœï¸ ConclusiÃ³n
El taller permitiÃ³ aplicar de forma integral los conceptos de **anÃ¡lisis estadÃ­stico y cientÃ­fico de datos** mediante Python.  
A travÃ©s de las librerÃ­as NumPy, Pandas, Matplotlib, Seaborn, SciPy y Scikit-learn, se abordaron desde cÃ¡lculos descriptivos hasta pruebas de hipÃ³tesis, reforzando la relaciÃ³n entre teorÃ­a y prÃ¡ctica.

Se concluye que:
- Las notas de los estudiantes presentan **asimetrÃ­a leve y no normalidad**.  
- El **Teorema del LÃ­mite Central** y las **distribuciones teÃ³ricas** se verifican empÃ­ricamente.  
- Las **correlaciones y pruebas inferenciales** complementan el anÃ¡lisis descriptivo, mostrando cÃ³mo los mÃ©todos estadÃ­sticos son esenciales en Inteligencia Artificial y ciencia de datos aplicada.

---

ğŸ“ **Repositorio GitHub:**  
ğŸ”— [AI-CLASS/IA_taller2_corte2](https://github.com/asrivasSW/AI-CLASS/tree/main/IA_taller2_corte2)
